{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86c61751",
   "metadata": {},
   "source": [
    "<h1>Install Libraries<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bd5fc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)  # Should show 4.57.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e690982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (25.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851eb408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.4.1)\n",
      "Requirement already satisfied: soundfile in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: librosa in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: jiwer in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: noisereduce in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dilit\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dilit\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.62.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\dilit\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: torch==2.9.1 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchaudio) (2.9.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.9.1->torchaudio) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.9.1->torchaudio) (3.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.9.1->torchaudio) (3.1.6)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: click>=8.1.8 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jiwer) (8.3.1)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jiwer) (3.14.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dilit\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0->soundfile) (2.23)\n",
      "Requirement already satisfied: colorama in c:\\users\\dilit\\appdata\\roaming\\python\\python311\\site-packages (from click>=8.1.8->jiwer) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from numba>=0.51.0->librosa) (0.45.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\dilit\\appdata\\roaming\\python\\python311\\site-packages (from pooch>=1.1->librosa) (4.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dilit\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch==2.9.1->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch==2.9.1->torchaudio) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets soundfile librosa torchaudio scikit-learn jiwer seaborn matplotlib noisereduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b24251c",
   "metadata": {},
   "source": [
    "<h1>Imports<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4520dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "\n",
    "from datasets import Dataset, Audio\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import (\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    Wav2Vec2ForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30067065",
   "metadata": {},
   "source": [
    "<h1>Load Label CSV<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1f4b892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>emotion_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...</td>\n",
       "      <td>calm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path emotion_label\n",
       "0  C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...       neutral\n",
       "1  C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...       neutral\n",
       "2  C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...       neutral\n",
       "3  C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...       neutral\n",
       "4  C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...          calm"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\dilit\\\\OneDrive - Sri Lanka Institute of Information Technology\\\\Research\\\\ai-powered-interview-training-voicebot\\\\backend\\\\app\\\\inputs\\\\labels_from_filenames.csv\")\n",
    "df = df[[\"file_path\", \"emotion_label\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6334a5c",
   "metadata": {},
   "source": [
    "<h1>Encode Emotion Labels<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba72a4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>emotion_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...</td>\n",
       "      <td>calm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path emotion_label  label\n",
       "0  C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...       neutral      5\n",
       "1  C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...       neutral      5\n",
       "2  C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...       neutral      5\n",
       "3  C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...       neutral      5\n",
       "4  C:\\Users\\dilit\\OneDrive - Sri Lanka Institute ...          calm      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_list = sorted(df[\"emotion_label\"].unique())\n",
    "\n",
    "label2id = {emotion: i for i, emotion in enumerate(emotion_list)}\n",
    "id2label = {i: emotion for emotion, i in label2id.items()}\n",
    "\n",
    "df[\"label\"] = df[\"emotion_label\"].map(label2id)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d201101",
   "metadata": {},
   "source": [
    "<h1>Audio Preprocessing Function<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6286a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(file_path, target_sr=16000):\n",
    "    # Load audio\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "    # 1. Noise Reduction\n",
    "    reduced_noise = nr.reduce_noise(y=audio, sr=sr)\n",
    "\n",
    "    # 2. Trim leading & trailing silence\n",
    "    trimmed, _ = librosa.effects.trim(reduced_noise, top_db=20)\n",
    "\n",
    "    # 3. Normalization\n",
    "    normalized = librosa.util.normalize(trimmed)\n",
    "\n",
    "    # 4. Resample to 16k Hz\n",
    "    if sr != target_sr:\n",
    "        normalized = librosa.resample(normalized, orig_sr=sr, target_sr=target_sr)\n",
    "\n",
    "    return normalized, target_sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15220837",
   "metadata": {},
   "source": [
    "<h1>Assign Preprocessing to the dataset<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27beb15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1320/1320 [03:15<00:00,  6.75 examples/s]\n",
      "Map: 100%|██████████| 1320/1320 [03:15<00:00,  6.75 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Add audio loading\n",
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "def load_and_preprocess(batch):\n",
    "    audio_array, sr = preprocess_audio(batch[\"file_path\"])\n",
    "    batch[\"audio\"] = {\"array\": audio_array, \"sampling_rate\": sr}\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(load_and_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0fdd85",
   "metadata": {},
   "source": [
    "<h1>Feature Extraction<h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0c626d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-960h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252bda8",
   "metadata": {},
   "source": [
    "<h1>Convert Audio to Model Input<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5cee482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1320/1320 [00:19<00:00, 66.74 examples/s]\n",
      "Map: 100%|██████████| 1320/1320 [00:19<00:00, 66.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def encode(batch):\n",
    "    audio = batch[\"audio\"][\"array\"]\n",
    "    sampling_rate = batch[\"audio\"][\"sampling_rate\"]\n",
    "\n",
    "    # Don't pad here; let the data collator handle padding at batch time.\n",
    "    inputs = feature_extractor(\n",
    "        audio,\n",
    "        sampling_rate=sampling_rate,\n",
    "        max_length=160000,  # around 10 sec max audio\n",
    "        truncation=True,\n",
    "    )\n",
    "    # Ensure input_values is a plain 1D Python list (not numpy nor nested list)\n",
    "    iv = inputs.get(\"input_values\")\n",
    "    # handle numpy arrays\n",
    "    try:\n",
    "        import numpy as _np\n",
    "        if isinstance(iv, _np.ndarray):\n",
    "            iv = _np.squeeze(iv).tolist()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # handle nested lists like [[...]]\n",
    "    if isinstance(iv, list) and len(iv) > 0 and isinstance(iv[0], (list, tuple)):\n",
    "        # flatten 1-element nesting\n",
    "        if len(iv) == 1:\n",
    "            iv = iv[0]\n",
    "        else:\n",
    "            # otherwise, try to flatten one level\n",
    "            flat = []\n",
    "            for e in iv:\n",
    "                if isinstance(e, (list, tuple)):\n",
    "                    flat.extend(e)\n",
    "                else:\n",
    "                    flat.append(e)\n",
    "            iv = flat\n",
    "    inputs[\"input_values\"] = iv\n",
    "    # Ensure labels are scalars\n",
    "    inputs[\"labels\"] = int(batch[\"label\"]) if batch.get(\"label\") is not None else None\n",
    "    return inputs\n",
    "\n",
    "dataset = dataset.map(\n",
    "    encode,\n",
    "    remove_columns=[\"file_path\", \"emotion_label\", \"audio\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545aea76",
   "metadata": {},
   "source": [
    "<h1>Train and Test Split<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ab03627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] type(input_values)=<class 'list'>; sample len=1\n",
      "    sample type first element: <class 'list'>\n",
      "    label type: <class 'int'>; value: 5\n",
      "------------------------------------------------------------\n",
      "[1] type(input_values)=<class 'list'>; sample len=1\n",
      "    sample type first element: <class 'list'>\n",
      "    label type: <class 'int'>; value: 7\n",
      "------------------------------------------------------------\n",
      "[2] type(input_values)=<class 'list'>; sample len=1\n",
      "    sample type first element: <class 'list'>\n",
      "    label type: <class 'int'>; value: 0\n",
      "------------------------------------------------------------\n",
      "[3] type(input_values)=<class 'list'>; sample len=1\n",
      "    sample type first element: <class 'list'>\n",
      "    label type: <class 'int'>; value: 1\n",
      "------------------------------------------------------------\n",
      "[4] type(input_values)=<class 'list'>; sample len=1\n",
      "    sample type first element: <class 'list'>\n",
      "    label type: <class 'int'>; value: 1\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Diagnostic cell: print types, shapes and sample values for a few dataset entries so we can see what's fed\n",
    "to the collator and detect any nested/inhomogeneous sequences.\n",
    "\"\"\"\n",
    "from pprint import pprint\n",
    "sample_size = min(5, len(train_ds))\n",
    "for i in range(sample_size):\n",
    "    s = train_ds[i]\n",
    "    iv = s.get('input_values')\n",
    "    lab = s.get('labels') or s.get('label')\n",
    "    print(f'[{i}] type(input_values)={type(iv)}; sample len=', end='')\n",
    "    try:\n",
    "        print(len(iv))\n",
    "    except Exception:\n",
    "        print('N/A')\n",
    "    print(f'    sample type first element: {type(iv[0]) if (hasattr(iv, \"__len__\") and len(iv)>0) else None}')\n",
    "    print(f'    label type: {type(lab)}; value: {lab}')\n",
    "    print('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f316e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_ds = split[\"train\"]\n",
    "val_ds = split[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecc3e70",
   "metadata": {},
   "source": [
    "<h1>Load wav2vec2 Model<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e2f0b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-960h\",\n",
    "    num_labels=len(emotion_list),\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "988c9751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/wav2vec2-large-960h/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002D769DFB010>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 5b0f4ad3-8860-4495-9881-6e79f925cab9)')' thrown while requesting HEAD https://huggingface.co/facebook/wav2vec2-large-960h/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/wav2vec2-large-960h/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002D769D84890>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: c37253ea-a978-4950-9ae7-802fbfca447a)')' thrown while requesting HEAD https://huggingface.co/facebook/wav2vec2-large-960h/resolve/main/config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/wav2vec2-large-960h/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002D769D84890>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: c37253ea-a978-4950-9ae7-802fbfca447a)')' thrown while requesting HEAD https://huggingface.co/facebook/wav2vec2-large-960h/resolve/main/config.json\n",
      "Retrying in 2s [Retry 2/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/wav2vec2-large-960h/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002D769D6B050>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 4551ae0e-a54c-4eb6-a973-3f487f6e6073)')' thrown while requesting HEAD https://huggingface.co/facebook/wav2vec2-large-960h/resolve/main/config.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/wav2vec2-large-960h/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002D769D6B050>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 4551ae0e-a54c-4eb6-a973-3f487f6e6073)')' thrown while requesting HEAD https://huggingface.co/facebook/wav2vec2-large-960h/resolve/main/config.json\n",
      "Retrying in 4s [Retry 3/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/wav2vec2-large-960h/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002D769D5CF90>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: db52be14-3c1f-41d7-9041-9e43c90cfb12)')' thrown while requesting HEAD https://huggingface.co/facebook/wav2vec2-large-960h/resolve/main/config.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/wav2vec2-large-960h/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002D769D5CF90>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: db52be14-3c1f-41d7-9041-9e43c90cfb12)')' thrown while requesting HEAD https://huggingface.co/facebook/wav2vec2-large-960h/resolve/main/config.json\n",
      "Retrying in 8s [Retry 4/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/wav2vec2-large-960h/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002D76923B0D0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 7c312672-c638-4913-a26b-eb8490272017)')' thrown while requesting HEAD https://huggingface.co/facebook/wav2vec2-large-960h/resolve/main/config.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/wav2vec2-large-960h/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002D76923B0D0>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 7c312672-c638-4913-a26b-eb8490272017)')' thrown while requesting HEAD https://huggingface.co/facebook/wav2vec2-large-960h/resolve/main/config.json\n",
      "Retrying in 8s [Retry 5/5].\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/wav2vec2-large-960h/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002D769DAF450>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 5b68953d-e662-42f0-ba16-74dfa20b52ff)')' thrown while requesting HEAD https://huggingface.co/facebook/wav2vec2-large-960h/resolve/main/config.json\n",
      "'(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /facebook/wav2vec2-large-960h/resolve/main/config.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002D769DAF450>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: 5b68953d-e662-42f0-ba16-74dfa20b52ff)')' thrown while requesting HEAD https://huggingface.co/facebook/wav2vec2-large-960h/resolve/main/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dilit\\.cache\\huggingface\\hub\\models--facebook--wav2vec2-large-960h\\snapshots\\bdeaacdf88f7a155f50a2704bc967aa81fbbb2ab\\config.json\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "path = hf_hub_download(\"facebook/wav2vec2-large-960h\", \"config.json\")\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca2f7be",
   "metadata": {},
   "source": [
    "<h1>Metrics (Accuracy, Precision, Recall, F1)<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "719195a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    labels = pred.label_ids\n",
    "\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='weighted'\n",
    "    )\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123435b5",
   "metadata": {},
   "source": [
    "<h1>Training Arguments<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58f800c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\dilit\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dilit\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\dilit\\appdata\\roaming\\python\\python311\\site-packages (from accelerate) (7.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dilit\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dilit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021F5EDF4B50>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/torch/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021F62B0E790>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/torch/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021F62B0F1D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/torch/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021F62B0FF10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/torch/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021F62B28B90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/torch/\n",
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021F62B2D6D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/transformers/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021F62B2E450>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/transformers/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021F62B2ED90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/transformers/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021F62B2F950>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/transformers/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021F62B04A90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/transformers/\n",
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021F62B0F010>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/accelerate/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021F62B0EB90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/accelerate/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021F62B0F110>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/accelerate/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021F62B38950>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/accelerate/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x0000021F62B39410>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /simple/accelerate/\n"
     ]
    }
   ],
   "source": [
    "# %pip install --upgrade pip\n",
    "%pip install --upgrade torch transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "283fd220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cpu\n",
      "4.57.3\n",
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "import accelerate\n",
    "\n",
    "print(torch.__version__)\n",
    "print(transformers.__version__)\n",
    "print(accelerate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c5b8fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu122\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002CA0BC5D490>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /whl/cu122/torch/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002CA0BC5E110>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /whl/cu122/torch/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002CA0BC5ED10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /whl/cu122/torch/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002CA0BC5F750>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /whl/cu122/torch/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002CA0BC78510>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /whl/cu122/torch/\n",
      "ERROR: Could not find a version that satisfies the requirement torch (from versions: none)\n",
      "ERROR: No matching distribution found for torch\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca54d9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.57.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b552833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n",
      "Package                 Version\n",
      "----------------------- -----------\n",
      "accelerate              1.12.0\n",
      "aiohappyeyeballs        2.6.1\n",
      "aiohttp                 3.13.2\n",
      "aiosignal               1.4.0\n",
      "anyio                   4.12.0\n",
      "asttokens               3.0.1\n",
      "attrs                   25.4.0\n",
      "audioread               3.1.0\n",
      "certifi                 2025.11.12\n",
      "cffi                    2.0.0\n",
      "charset-normalizer      3.4.4\n",
      "click                   8.3.1\n",
      "colorama                0.4.6\n",
      "comm                    0.2.3\n",
      "contourpy               1.3.3\n",
      "cycler                  0.12.1\n",
      "datasets                4.4.1\n",
      "debugpy                 1.8.17\n",
      "decorator               5.2.1\n",
      "dill                    0.4.0\n",
      "executing               2.2.1\n",
      "filelock                3.20.0\n",
      "fonttools               4.61.0\n",
      "frozenlist              1.8.0\n",
      "fsspec                  2025.10.0\n",
      "h11                     0.16.0\n",
      "httpcore                1.0.9\n",
      "httpx                   0.28.1\n",
      "huggingface-hub         0.36.0\n",
      "idna                    3.11\n",
      "ipykernel               7.1.0\n",
      "ipython                 9.7.0\n",
      "ipython_pygments_lexers 1.1.1\n",
      "jedi                    0.19.2\n",
      "Jinja2                  3.1.6\n",
      "jiwer                   4.0.0\n",
      "joblib                  1.5.2\n",
      "jupyter_client          8.6.3\n",
      "jupyter_core            5.9.1\n",
      "kiwisolver              1.4.9\n",
      "lazy_loader             0.4\n",
      "librosa                 0.11.0\n",
      "llvmlite                0.45.1\n",
      "MarkupSafe              3.0.3\n",
      "matplotlib              3.10.7\n",
      "matplotlib-inline       0.2.1\n",
      "mpmath                  1.3.0\n",
      "msgpack                 1.1.2\n",
      "multidict               6.7.0\n",
      "multiprocess            0.70.18\n",
      "nest-asyncio            1.6.0\n",
      "networkx                3.6\n",
      "noisereduce             3.0.3\n",
      "numba                   0.62.1\n",
      "numpy                   2.3.5\n",
      "packaging               25.0\n",
      "pandas                  2.3.3\n",
      "parso                   0.8.5\n",
      "pillow                  12.0.0\n",
      "pip                     25.3\n",
      "platformdirs            4.5.0\n",
      "pooch                   1.8.2\n",
      "prompt_toolkit          3.0.52\n",
      "propcache               0.4.1\n",
      "psutil                  7.1.3\n",
      "pure_eval               0.2.3\n",
      "pyarrow                 22.0.0\n",
      "pycparser               2.23\n",
      "Pygments                2.19.2\n",
      "pyparsing               3.2.5\n",
      "python-dateutil         2.9.0.post0\n",
      "pytz                    2025.2\n",
      "PyYAML                  6.0.3\n",
      "pyzmq                   27.1.0\n",
      "RapidFuzz               3.14.3\n",
      "regex                   2025.11.3\n",
      "requests                2.32.5\n",
      "safetensors             0.7.0\n",
      "scikit-learn            1.7.2\n",
      "scipy                   1.16.3\n",
      "seaborn                 0.13.2\n",
      "setuptools              65.5.0\n",
      "six                     1.17.0\n",
      "soundfile               0.13.1\n",
      "soxr                    1.0.0\n",
      "stack-data              0.6.3\n",
      "sympy                   1.14.0\n",
      "threadpoolctl           3.6.0\n",
      "tokenizers              0.22.1\n",
      "torch                   2.9.1\n",
      "torchaudio              2.9.1\n",
      "tornado                 6.5.2\n",
      "tqdm                    4.67.1\n",
      "traitlets               5.14.3\n",
      "transformers            4.57.3\n",
      "typing_extensions       4.15.0\n",
      "tzdata                  2025.2\n",
      "urllib3                 2.5.0\n",
      "wcwidth                 0.2.14\n",
      "xxhash                  3.6.0\n",
      "yarl                    1.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Package                 Version\n",
      "----------------------- -----------\n",
      "accelerate              1.12.0\n",
      "aiohappyeyeballs        2.6.1\n",
      "aiohttp                 3.13.2\n",
      "aiosignal               1.4.0\n",
      "anyio                   4.12.0\n",
      "asttokens               3.0.1\n",
      "attrs                   25.4.0\n",
      "audioread               3.1.0\n",
      "certifi                 2025.11.12\n",
      "cffi                    2.0.0\n",
      "charset-normalizer      3.4.4\n",
      "click                   8.3.1\n",
      "colorama                0.4.6\n",
      "comm                    0.2.3\n",
      "contourpy               1.3.3\n",
      "cycler                  0.12.1\n",
      "datasets                4.4.1\n",
      "debugpy                 1.8.17\n",
      "decorator               5.2.1\n",
      "dill                    0.4.0\n",
      "executing               2.2.1\n",
      "filelock                3.20.0\n",
      "fonttools               4.61.0\n",
      "frozenlist              1.8.0\n",
      "fsspec                  2025.10.0\n",
      "h11                     0.16.0\n",
      "httpcore                1.0.9\n",
      "httpx                   0.28.1\n",
      "huggingface-hub         0.36.0\n",
      "idna                    3.11\n",
      "ipykernel               7.1.0\n",
      "ipython                 9.7.0\n",
      "ipython_pygments_lexers 1.1.1\n",
      "jedi                    0.19.2\n",
      "Jinja2                  3.1.6\n",
      "jiwer                   4.0.0\n",
      "joblib                  1.5.2\n",
      "jupyter_client          8.6.3\n",
      "jupyter_core            5.9.1\n",
      "kiwisolver              1.4.9\n",
      "lazy_loader             0.4\n",
      "librosa                 0.11.0\n",
      "llvmlite                0.45.1\n",
      "MarkupSafe              3.0.3\n",
      "matplotlib              3.10.7\n",
      "matplotlib-inline       0.2.1\n",
      "mpmath                  1.3.0\n",
      "msgpack                 1.1.2\n",
      "multidict               6.7.0\n",
      "multiprocess            0.70.18\n",
      "nest-asyncio            1.6.0\n",
      "networkx                3.6\n",
      "noisereduce             3.0.3\n",
      "numba                   0.62.1\n",
      "numpy                   2.3.5\n",
      "packaging               25.0\n",
      "pandas                  2.3.3\n",
      "parso                   0.8.5\n",
      "pillow                  12.0.0\n",
      "pip                     25.3\n",
      "platformdirs            4.5.0\n",
      "pooch                   1.8.2\n",
      "prompt_toolkit          3.0.52\n",
      "propcache               0.4.1\n",
      "psutil                  7.1.3\n",
      "pure_eval               0.2.3\n",
      "pyarrow                 22.0.0\n",
      "pycparser               2.23\n",
      "Pygments                2.19.2\n",
      "pyparsing               3.2.5\n",
      "python-dateutil         2.9.0.post0\n",
      "pytz                    2025.2\n",
      "PyYAML                  6.0.3\n",
      "pyzmq                   27.1.0\n",
      "RapidFuzz               3.14.3\n",
      "regex                   2025.11.3\n",
      "requests                2.32.5\n",
      "safetensors             0.7.0\n",
      "scikit-learn            1.7.2\n",
      "scipy                   1.16.3\n",
      "seaborn                 0.13.2\n",
      "setuptools              65.5.0\n",
      "six                     1.17.0\n",
      "soundfile               0.13.1\n",
      "soxr                    1.0.0\n",
      "stack-data              0.6.3\n",
      "sympy                   1.14.0\n",
      "threadpoolctl           3.6.0\n",
      "tokenizers              0.22.1\n",
      "torch                   2.9.1\n",
      "torchaudio              2.9.1\n",
      "tornado                 6.5.2\n",
      "tqdm                    4.67.1\n",
      "traitlets               5.14.3\n",
      "transformers            4.57.3\n",
      "typing_extensions       4.15.0\n",
      "tzdata                  2025.2\n",
      "urllib3                 2.5.0\n",
      "wcwidth                 0.2.14\n",
      "xxhash                  3.6.0\n",
      "yarl                    1.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8009b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Filtered TrainingArgs keys: ['eval_steps', 'eval_strategy', 'fp16', 'learning_rate', 'load_best_model_at_end', 'logging_steps', 'num_train_epochs', 'output_dir', 'per_device_eval_batch_size', 'per_device_train_batch_size', 'save_steps', 'save_strategy', 'save_total_limit', 'warmup_steps']\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments in a way that is compatible across Transformers versions\n",
    "from transformers import TrainingArguments\n",
    "from packaging import version\n",
    "import transformers as _transformers\n",
    "\n",
    "transformers_version = _transformers.__version__\n",
    "\n",
    "training_kwargs = dict(\n",
    "    output_dir=\"./wav2vec2_emotion_preprocessed\",\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=200,\n",
    "    logging_steps=20,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=False,  # CPU only\n",
    "    # Prefer eval_steps/save_steps for backward compatibility\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    ")\n",
    "\n",
    "# Add evaluation/save strategy only if the TrainingArguments signature accepts them\n",
    "import inspect\n",
    "from transformers import TrainingArguments as _TrainingArguments\n",
    "\n",
    "# Inspect TrainingArguments signature and filter kwargs to avoid passing unsupported keys\n",
    "sig = inspect.signature(_TrainingArguments.__init__)\n",
    "# Allowed param names in TrainingArguments.__init__ (exclude self and kwargs)\n",
    "allowed_param_names = {name for name in sig.parameters.keys() if name not in ('self', 'kwargs')}\n",
    "\n",
    "# Add evaluation/save strategy only if supported\n",
    "# Find the canonical parameter name for evaluation strategy in this Transformers version: `evaluation_strategy` or `eval_strategy`.\n",
    "eval_param = None\n",
    "if 'evaluation_strategy' in allowed_param_names:\n",
    "    eval_param = 'evaluation_strategy'\n",
    "elif 'eval_strategy' in allowed_param_names:\n",
    "    eval_param = 'eval_strategy'\n",
    "\n",
    "if 'save_strategy' in allowed_param_names:\n",
    "    training_kwargs['save_strategy'] = 'steps'\n",
    "\n",
    "# If an eval parameter name exists, set it to match the save strategy to allow load_best_model_at_end\n",
    "if eval_param:\n",
    "    training_kwargs[eval_param] = 'steps'\n",
    "else:\n",
    "    # There is no evaluation strategy parameter; fall back to eval_steps & save_steps only.\n",
    "    # If load_best_model_at_end requires matching eval/save strategy, switch it off to avoid the ValueError.\n",
    "    if 'load_best_model_at_end' in training_kwargs and training_kwargs['load_best_model_at_end']:\n",
    "        print('# NOTE: Disabling load_best_model_at_end because evaluation strategy param is missing in this Transformers version')\n",
    "        training_kwargs['load_best_model_at_end'] = False\n",
    "\n",
    "# Filter training_kwargs to only include allowed parameters (prevent TypeError on unknown args)\n",
    "filtered_kwargs = {k: v for k, v in training_kwargs.items() if k in allowed_param_names}\n",
    "\n",
    "# Show what will be passed to TrainingArguments (helpful for debugging in notebook)\n",
    "print('# Filtered TrainingArgs keys:', sorted(filtered_kwargs.keys()))\n",
    "\n",
    "# Note: If you recently upgraded the `transformers` package in the same kernel, restart the kernel\n",
    "# to ensure imports/loading reflect the newly installed version (otherwise you may still see old signatures).\n",
    "\n",
    "training_args = TrainingArguments(**filtered_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c59ac08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers version: 4.57.3\n",
      "\n",
      "TrainingArguments signature:\n",
      "(self, output_dir: Optional[str] = None, overwrite_output_dir: bool = False, do_train: bool = False, do_eval: bool = False, do_predict: bool = False, eval_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'no', prediction_loss_only: bool = False, per_device_train_batch_size: int = 8, per_device_eval_batch_size: int = 8, per_gpu_train_batch_size: Optional[int] = None, per_gpu_eval_batch_size: Optional[int] = None, gradient_accumulation_steps: int = 1, eval_accumulation_steps: Optional[int] = None, eval_delay: float = 0, torch_empty_cache_steps: Optional[int] = None, learning_rate: float = 5e-05, weight_decay: float = 0.0, adam_beta1: float = 0.9, adam_beta2: float = 0.999, adam_epsilon: float = 1e-08, max_grad_norm: float = 1.0, num_train_epochs: float = 3.0, max_steps: int = -1, lr_scheduler_type: Union[transformers.trainer_utils.SchedulerType, str] = 'linear', lr_scheduler_kwargs: Union[dict[str, Any], str] = <factory>, warmup_ratio: float = 0.0, warmup_steps: int = 0, log_level: str = 'passive', log_level_replica: str = 'warning', log_on_each_node: bool = True, logging_dir: Optional[str] = None, logging_strategy: Union[transformers.trainer_utils.IntervalStrategy, str] = 'steps', logging_first_step: bool = False, logging_steps: float = 500, logging_nan_inf_filter: bool = True, save_strategy: Union[transformers.trainer_utils.SaveStrategy, str] = 'steps', save_steps: float = 500, save_total_limit: Optional[int] = None, save_safetensors: bool = True, save_on_each_node: bool = False, save_only_model: bool = False, restore_callback_states_from_checkpoint: bool = False, no_cuda: bool = False, use_cpu: bool = False, use_mps_device: bool = False, seed: int = 42, data_seed: Optional[int] = None, jit_mode_eval: bool = False, bf16: bool = False, fp16: bool = False, fp16_opt_level: str = 'O1', half_precision_backend: str = 'auto', bf16_full_eval: bool = False, fp16_full_eval: bool = False, tf32: Optional[bool] = None, local_rank: int = -1, ddp_backend: Optional[str] = None, tpu_num_cores: Optional[int] = None, tpu_metrics_debug: bool = False, debug: Union[str, list[transformers.debug_utils.DebugOption]] = '', dataloader_drop_last: bool = False, eval_steps: Optional[float] = None, dataloader_num_workers: int = 0, dataloader_prefetch_factor: Optional[int] = None, past_index: int = -1, run_name: Optional[str] = None, disable_tqdm: Optional[bool] = None, remove_unused_columns: bool = True, label_names: Optional[list[str]] = None, load_best_model_at_end: bool = False, metric_for_best_model: Optional[str] = None, greater_is_better: Optional[bool] = None, ignore_data_skip: bool = False, fsdp: Union[list[transformers.trainer_utils.FSDPOption], str, NoneType] = None, fsdp_min_num_params: int = 0, fsdp_config: Union[dict[str, Any], str, NoneType] = None, fsdp_transformer_layer_cls_to_wrap: Optional[str] = None, accelerator_config: Union[dict, str, NoneType] = None, parallelism_config: Optional[accelerate.parallelism_config.ParallelismConfig] = None, deepspeed: Union[dict, str, NoneType] = None, label_smoothing_factor: float = 0.0, optim: Union[transformers.training_args.OptimizerNames, str] = 'adamw_torch_fused', optim_args: Optional[str] = None, adafactor: bool = False, group_by_length: bool = False, length_column_name: str = 'length', report_to: Union[NoneType, str, list[str]] = None, project: str = 'huggingface', trackio_space_id: Optional[str] = 'trackio', ddp_find_unused_parameters: Optional[bool] = None, ddp_bucket_cap_mb: Optional[int] = None, ddp_broadcast_buffers: Optional[bool] = None, dataloader_pin_memory: bool = True, dataloader_persistent_workers: bool = False, skip_memory_metrics: bool = True, use_legacy_prediction_loop: bool = False, push_to_hub: bool = False, resume_from_checkpoint: Optional[str] = None, hub_model_id: Optional[str] = None, hub_strategy: Union[transformers.trainer_utils.HubStrategy, str] = 'every_save', hub_token: Optional[str] = None, hub_private_repo: Optional[bool] = None, hub_always_push: bool = False, hub_revision: Optional[str] = None, gradient_checkpointing: bool = False, gradient_checkpointing_kwargs: Union[dict[str, Any], str, NoneType] = None, include_inputs_for_metrics: bool = False, include_for_metrics: list[str] = <factory>, eval_do_concat_batches: bool = True, fp16_backend: str = 'auto', push_to_hub_model_id: Optional[str] = None, push_to_hub_organization: Optional[str] = None, push_to_hub_token: Optional[str] = None, mp_parameters: str = '', auto_find_batch_size: bool = False, full_determinism: bool = False, torchdynamo: Optional[str] = None, ray_scope: Optional[str] = 'last', ddp_timeout: int = 1800, torch_compile: bool = False, torch_compile_backend: Optional[str] = None, torch_compile_mode: Optional[str] = None, include_tokens_per_second: bool = False, include_num_input_tokens_seen: Union[str, bool] = False, neftune_noise_alpha: Optional[float] = None, optim_target_modules: Union[NoneType, str, list[str]] = None, batch_eval_metrics: bool = False, eval_on_start: bool = False, use_liger_kernel: bool = False, liger_kernel_config: Optional[dict[str, bool]] = None, eval_use_gather_object: bool = False, average_tokens_across_devices: bool = True) -> None\n",
      "\n",
      "Training args loaded:\n",
      " - load_best_model_at_end: True\n",
      " - evaluation strategy attr: eval_strategy\n",
      "   -> IntervalStrategy.STEPS\n",
      " - save_strategy: SaveStrategy.STEPS\n",
      " - eval_steps: 100\n",
      " - save_steps: 100\n"
     ]
    }
   ],
   "source": [
    "# Final verification: print Transformers version and check installed TrainingArguments parameters\n",
    "import inspect\n",
    "import transformers\n",
    "from transformers import TrainingArguments\n",
    "print('Transformers version:', transformers.__version__)\n",
    "print('\\nTrainingArguments signature:')\n",
    "print(inspect.signature(TrainingArguments.__init__))\n",
    "\n",
    "# Print the instantiated training_args properties for debugging\n",
    "try:\n",
    "    print('\\nTraining args loaded:')\n",
    "    print(' - load_best_model_at_end:', training_args.load_best_model_at_end)\n",
    "    # mapping for evaluation strategy attribute names\n",
    "    eval_attr = None\n",
    "    if hasattr(training_args, 'evaluation_strategy'):\n",
    "        eval_attr = 'evaluation_strategy'\n",
    "    elif hasattr(training_args, 'eval_strategy'):\n",
    "        eval_attr = 'eval_strategy'\n",
    "    print(' - evaluation strategy attr:', eval_attr)\n",
    "    if eval_attr:\n",
    "        print('   ->', getattr(training_args, eval_attr))\n",
    "    print(' - save_strategy:', getattr(training_args, 'save_strategy', None))\n",
    "    print(' - eval_steps:', getattr(training_args, 'eval_steps', None))\n",
    "    print(' - save_steps:', getattr(training_args, 'save_steps', None))\n",
    "except Exception as e:\n",
    "    print('Error while printing training args properties:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e43523c",
   "metadata": {},
   "source": [
    "<h1>Trainer<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21f1f063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding, Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=processor, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae9468b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=data_collator  # correct\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a0fde",
   "metadata": {},
   "source": [
    "<h1>Train the Model<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe0022ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[float], int]]]) -> Dict[str, torch.Tensor]:\n",
    "        # Extract input_values and labels, convert numpy arrays to Python lists to be padded by the processor\n",
    "        input_features = []\n",
    "        label_features = []\n",
    "        for f in features:\n",
    "            iv = f.get(\"input_values\")\n",
    "            # Normalize input_values to 1D Python list: handle numpy arrays, nested lists, or (n,1) shapes\n",
    "            try:\n",
    "                import numpy as _np\n",
    "                # Convert numpy arrays to list then flatten 1-element nesting\n",
    "                if hasattr(iv, \"tolist\"):\n",
    "                    iv = iv.tolist()\n",
    "                # If it's a nested list like [[...]] or list of arrays, convert & squeeze\n",
    "                if isinstance(iv, list) and len(iv) > 0 and isinstance(iv[0], (list, tuple, _np.ndarray)):\n",
    "                    arr = _np.asarray(iv)\n",
    "                    arr = _np.squeeze(arr)\n",
    "                    iv = arr.tolist()\n",
    "            except Exception:\n",
    "                # Fallback: try to flatten trivial nesting\n",
    "                if isinstance(iv, list) and len(iv) > 0 and isinstance(iv[0], (list, tuple)):\n",
    "                    if len(iv) == 1:\n",
    "                        iv = iv[0]\n",
    "            input_features.append({\"input_values\": iv})\n",
    "\n",
    "            lab = f.get(\"labels\")\n",
    "            # Ensure labels are ints (sequence classification expects scalar labels)\n",
    "            try:\n",
    "                lab_int = int(lab)\n",
    "            except Exception:\n",
    "                # Fallback: if it's an array or list, take the first element\n",
    "                if hasattr(lab, \"__len__\"):\n",
    "                    lab_int = int(lab[0])\n",
    "                else:\n",
    "                    lab_int = int(lab)\n",
    "            label_features.append(lab_int)\n",
    "\n",
    "        # Pad the input_values using processor (processor expects list of lists)\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Convert labels to tensor\n",
    "        batch[\"labels\"] = torch.tensor(label_features, dtype=torch.long)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4dd7ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Wav2Vec2Processor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load processor\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m processor = \u001b[43mWav2Vec2Processor\u001b[49m.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mfacebook/wav2vec2-base\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create collator\u001b[39;00m\n\u001b[32m      5\u001b[39m data_collator = DataCollatorCTCWithPadding(processor=processor, padding=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'Wav2Vec2Processor' is not defined"
     ]
    }
   ],
   "source": [
    "# Load processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "\n",
    "# Create collator\n",
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2926465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch keys: ['input_values', 'labels']\n",
      "input_values <class 'torch.Tensor'> torch.Size([4, 31062])\n",
      "labels <class 'torch.Tensor'> torch.Size([4])\n",
      "Sanity check OK — collator produced tensors\n"
     ]
    }
   ],
   "source": [
    "# Quick sanity test: run the collator on a small batch and inspect shapes\n",
    "from pprint import pprint\n",
    "try:\n",
    "    sample_features = [train_ds[i] for i in range(min(4, len(train_ds)))]\n",
    "    batch = data_collator(sample_features)\n",
    "    print('Batch keys:', list(batch.keys()))\n",
    "    for k, v in batch.items():\n",
    "        try:\n",
    "            print(k, type(v), v.shape)\n",
    "        except Exception:\n",
    "            print(k, type(v))\n",
    "    print('Sanity check OK — collator produced tensors')\n",
    "except Exception as e:\n",
    "    print('Collator test error:', type(e).__name__, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "093c927f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2640' max='2640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2640/2640 46:38:40, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.098600</td>\n",
       "      <td>2.080244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.073500</td>\n",
       "      <td>2.073848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.035800</td>\n",
       "      <td>2.065224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.129200</td>\n",
       "      <td>2.072175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.052400</td>\n",
       "      <td>2.067372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.037500</td>\n",
       "      <td>2.078077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.090700</td>\n",
       "      <td>2.068405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.089800</td>\n",
       "      <td>2.073665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.126300</td>\n",
       "      <td>2.080536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.093600</td>\n",
       "      <td>2.062241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.030400</td>\n",
       "      <td>2.087851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.078200</td>\n",
       "      <td>2.093312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>2.059900</td>\n",
       "      <td>2.075393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.084900</td>\n",
       "      <td>2.086092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.059700</td>\n",
       "      <td>2.068902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.067900</td>\n",
       "      <td>2.074058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>2.077300</td>\n",
       "      <td>2.080627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.110100</td>\n",
       "      <td>2.067610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>2.047200</td>\n",
       "      <td>2.070004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>2.068443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>2.091700</td>\n",
       "      <td>2.063034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.080500</td>\n",
       "      <td>2.059814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>2.039000</td>\n",
       "      <td>2.060920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.011200</td>\n",
       "      <td>2.059529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.068000</td>\n",
       "      <td>2.060841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.095100</td>\n",
       "      <td>2.061477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\dilit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2640, training_loss=2.0711076259613037, metrics={'train_runtime': 167944.5913, 'train_samples_per_second': 0.031, 'train_steps_per_second': 0.016, 'total_flos': 2.7919664495120093e+17, 'train_loss': 2.0711076259613037, 'epoch': 5.0})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94015eaf",
   "metadata": {},
   "source": [
    "<h1>Save the Train Model<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57557f81",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# STEP 17 — Save final model and processor\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrainer\u001b[49m.save_model(\u001b[33m\"\u001b[39m\u001b[33m./wav2vec2_emotion_model\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m processor.save_pretrained(\u001b[33m\"\u001b[39m\u001b[33m./wav2vec2_emotion_model\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# STEP 17 — Save final model and processor\n",
    "trainer.save_model(\"./wav2vec2_emotion_model\")\n",
    "processor.save_pretrained(\"./wav2vec2_emotion_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f66241f",
   "metadata": {},
   "source": [
    "<h1>Evaluate the Model<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96c2fd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m metrics = \u001b[43mtrainer\u001b[49m.evaluate()\n\u001b[32m      2\u001b[39m metrics\n",
      "\u001b[31mNameError\u001b[39m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af499a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
